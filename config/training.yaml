training:
  batch_size: 8
  n_epochs: 20
  learning_rate: 0.0001
  learning_rate_decay_steps: [3, 8]
  learning_rate_decay_values: 0.5
  n_workers: 2
  # test_checkpoint_path: None #/Users/vtokala/Documents/Research/di_nn/DCNN/checkpoints/weights-epoch=35-validation_loss=-0.61.ckpt # Model to be used when analyzing the results
  # train_checkpoint_path: None #/Users/ezajlerg/src/SE_DCNN/demo/weights-epoch=19-validation_loss=-17.90.ckpt # Start training using this pretrained model

  strategy: ddp # defines how data is shared when using multiple GPUs 
  pin_memory: False
  accelerator: null
  early_stopping:
    enabled: True
    key_to_monitor: validation_loss
    min_delta: 0.01
    patience_in_epochs: 3